input {
  file {
    path => "/usr/share/logstash/network_security_logs.csv"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter {
  csv {
    separator => ","
    columns => ["timestamp", "source_port", "destination_port", "protocol", "action", "bytes_sent", "bytes_received", "threat_level", "latitude", "longitude"]
  }

  mutate {
    # Ajoute un nom d'index dynamique basé sur la date
    add_field => { "[@metadata][index]" => "iot-security-%{+YYYY.MM.dd}" }

    # Convertit les ports et les données en nombres
    convert => {
      "source_port" => "integer"
      "destination_port" => "integer"
      "bytes_sent" => "integer"
      "bytes_received" => "integer"
      "latitude" => "float"
      "longitude" => "float"
    }

    # Crée un champ geo_point pour Elasticsearch
    add_field => {
      "[location]" => "%{latitude},%{longitude}"
    }
  }

  # Parse la date ISO8601 vers le champ spécial @timestamp
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }

  # Transforme la string en tableau de 2 floats pour geo_point
  mutate {
    split => ["[location]", ","]
    convert => { "[location][0]" => "float" }
    convert => { "[location][1]" => "float" }
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "%{[@metadata][index]}"
  }

  stdout {
    codec => rubydebug
  }
}
