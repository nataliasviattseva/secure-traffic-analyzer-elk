# Entrée : Logstash écoute sur le port TCP 5045 et attend des données JSON
input {
  file {
        path => "/usr/share/logstash/network_security_logs.csv"
        start_position => "beginning"
        sincedb_path => "/dev/null"
  }

}

# Filtrage : transformation et enrichissement des données
filter {
  # Le bloc 'csv' permet de transformer chaque ligne du fichier CSV en un document avec des champs nommés
  csv {
        separator => ","
        columns => ["timestamp", "source_port", "destination_port", "protocol", "action", "bytes_sent", "bytes_received", "threat_level"]
  }

  mutate {
    # Ajoute dynamiquement un nom d'index basé sur la date actuelle
    add_field => { "[@metadata][index]" => "iot-security-%{+YYYY.MM.dd}" }
  }

  date {
    # Transforme le champ "timestamp" en champ spécial @timestamp utilisé dans Kibana
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }

  
}

# Sortie : envoi des données vers Elasticsearch et vers la console pour debug
output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]  # Adresse du service Elasticsearch
    index => "%{[@metadata][index]}"        # Utilisation du nom d'index dynamique
  }

  stdout {
    codec => rubydebug  # Affiche les événements formatés dans la console Logstash
  }
}
