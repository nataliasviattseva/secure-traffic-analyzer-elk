# Entrée : Logstash écoute sur le port TCP 5045 et attend des données JSON
input {
  tcp {
    port => 5045   # Port d'écoute pour recevoir les messages JSON simulés
    codec => json_lines  # Les messages reçus sont automatiquement interprétés comme JSON
  }
}

# Filtrage : transformation et enrichissement des données
filter {
  mutate {
    # Ajoute dynamiquement un nom d'index basé sur la date actuelle
    add_field => { "[@metadata][index]" => "iot-smartcity-%{+YYYY.MM.dd}" }
  }

  date {
    # Transforme le champ "timestamp" en champ spécial @timestamp utilisé dans Kibana
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }

  mutate {
    # Aplatit les champs imbriqués JSON
    # Ex : metrics.pm2_5 devient simplement pm2_5
    rename => { "metrics.pm2_5"     => "pm2_5" }
    rename => { "metrics.co2"       => "co2" }
    rename => { "metrics.temperature" => "temperature" }
    rename => { "metrics.humidity"  => "humidity" }
    rename => { "location.lat"      => "latitude" }
    rename => { "location.lon"      => "longitude" }
    add_field => { "[@metadata][index]" => "iot-smartcity-%{+YYYY.MM.dd}" }
  }
}

# Sortie : envoi des données vers Elasticsearch et vers la console pour debug
output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]  # Adresse du service Elasticsearch
    index => "%{[@metadata][index]}"        # Utilisation du nom d'index dynamique
  }

  stdout {
    codec => rubydebug  # Affiche les événements formatés dans la console Logstash
  }
}
